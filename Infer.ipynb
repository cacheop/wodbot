{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import helper\n",
    "\n",
    "_, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()\n",
    "seq_length, load_dir = helper.load_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tensors(loaded_graph):\n",
    "    return \\\n",
    "        loaded_graph.get_tensor_by_name(\"input:0\"), \\\n",
    "        loaded_graph.get_tensor_by_name(\"initial_state:0\"), \\\n",
    "        loaded_graph.get_tensor_by_name(\"final_state:0\"), \\\n",
    "        loaded_graph.get_tensor_by_name(\"probs:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pick_word(probabilities, int_to_vocab):\n",
    "    possibilities = []\n",
    "    for ix, prob in enumerate(probabilities):\n",
    "        if prob >= .05:\n",
    "            possibilities.append(int_to_vocab[ix])\n",
    "    rand = np.random.randint(0, len(possibilities))\n",
    "    \n",
    "    return str(possibilities[rand])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save\n",
      "shots, 20/14 pounds s ]\n",
      "-----------------\n",
      "[ 24 minutes; 6 rounds; 2 min on/2 min off; rd 1-3 -5; 250 m row -> max box jumps 30/24; rd 246; 15/10 calories on the air dyne > max kettlebell sumo deadlift high-pull 70/53 pounds; 24/20 box; 53/35 pounds kettlebell ]\n",
      "-----------------\n",
      "[ 24 minute amrap; 200m run; 12 hang squat cleans 135/95 pounds; 24/20; max unbroken ttb ]\n",
      "-----------------\n",
      "[ 8 min amrap; 50 wall balls 16/12 pounds; 50 unbroken double-unders ]\n",
      "-----------------\n",
      "[ 8 min cap; 10-8-6-4-2 reps:, for time 135/95; 75 burpees; 50 wall balls, 20/14 pounds ]\n",
      "-----------------\n",
      "[ 15 ]2; every 3 minutes and; cash out: 70 unbroken double-unders; min 3: 5 rounds for time; 12 snatch; 12 pull-ups; 2 minutes on rower(5) and stop on 30 seconds ]\n",
      "-----------------\n",
      "[ coach leads group through 3 rounds of: 5 light renegade rows; 10 jumping air squats; 14 straight leg march w/alternate toe touches; clean grip deadlift w/ pause 2” off ground top of knee; 70×5, 80×5(3); with 10 seconds hold @ knee on way back down to the floor; push up x 10 reps:(3 count descent); rest 5 minutes; 30 seconds of movement on a; renegade rows; x 3 rounds ]\n",
      "-----------------\n",
      "[ back squat; 50×2; 60×2; 70×2; 80×1; then 2-3 more singles from here to the hang position(video); then drop down 50-60% and work on barbell cycling for the complex: 1 push-press, 1 rep max burpees, building for max distance; part 1, three rounds) complete the following as above 50 meters, then; 5, squats, 13 push-ups; 15 box jumps, 30 in the ring rows); 200 meters run; rest 90 seconds bt rounds; 14 minutes on row; teams of 3; 1500 m in strict handstand push-ups; for the top of pull-ups and progressions; your partner to find a heavy rest, for 15 seconds\n"
     ]
    }
   ],
   "source": [
    "gen_length = 380\n",
    "prime_word = 'shots'\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "    loader.restore(sess, load_dir)\n",
    "\n",
    "    # Get Tensors from loaded model\n",
    "    input_text, initial_state, final_state, probs = get_tensors(loaded_graph)\n",
    "\n",
    "    # Sentences generation setup\n",
    "    gen_sentences = [prime_word]\n",
    "    prev_state = sess.run(initial_state, {input_text: np.array([[1]])})\n",
    "\n",
    "    # Generate sentences\n",
    "    for n in range(gen_length):\n",
    "        # Dynamic Input\n",
    "        dyn_input = [[vocab_to_int[word] for word in gen_sentences[-seq_length:]]]\n",
    "        dyn_seq_length = len(dyn_input[0])\n",
    "\n",
    "        # Get Prediction\n",
    "        probabilities, prev_state = sess.run(\n",
    "            [probs, final_state],\n",
    "            {input_text: dyn_input, initial_state: prev_state})\n",
    "        \n",
    "        pred_word = pick_word(probabilities[dyn_seq_length-1], int_to_vocab)\n",
    "\n",
    "        gen_sentences.append(pred_word)\n",
    "    \n",
    "    # Remove tokens\n",
    "    tv_script = ' '.join(gen_sentences)\n",
    "    for key, token in token_dict.items():\n",
    "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
    "        tv_script = tv_script.replace(' ' + token.lower(), key)\n",
    "    tv_script = tv_script.replace('\\n ', '\\n-----------------\\n')\n",
    "    tv_script = tv_script.replace('( ', '(')\n",
    "    \n",
    "    print(tv_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
